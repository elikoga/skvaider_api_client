{
  "model": "gpt-oss:120b",
  "max_tokens": 100,
  "method": "mixed_parallel_batch",
  "timestamp": 1770288156.304725,
  "total_prompts": 16,
  "total_tokens": 1600,
  "total_time": 8.19663691520691,
  "average_tokens_per_second": 195.20200986719087,
  "batch_results": [
    {
      "batch_idx": 0,
      "batch_size": 16,
      "tokens": 1600,
      "time": 8.19663691520691,
      "tokens_per_second": 195.20200986719087,
      "requests": 16
    }
  ]
}