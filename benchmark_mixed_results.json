{
  "model": "gpt-oss:120b",
  "max_tokens": 100,
  "method": "mixed_parallel_batch",
  "timestamp": 1770287305.257647,
  "total_prompts": 16,
  "total_tokens": 1600,
  "total_time": 7.926114797592163,
  "average_tokens_per_second": 201.86434853126988,
  "batch_results": [
    {
      "batch_idx": 0,
      "requests": 16,
      "tokens": 1600,
      "time": 7.926114797592163,
      "tokens_per_second": 201.86434853126988
    }
  ]
}