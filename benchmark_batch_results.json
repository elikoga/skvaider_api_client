{
  "model": "gpt-oss:120b",
  "max_tokens": 100,
  "method": "batch_api",
  "timestamp": 1770287783.029208,
  "results": [
    {
      "batch_size": 64,
      "total_prompts": 6,
      "total_tokens": 600,
      "total_time": 3.9640278816223145,
      "average_tokens_per_second": 151.36119571248943,
      "batch_results": [
        {
          "batch_idx": 0,
          "batch_size": 6,
          "tokens": 600,
          "time": 3.9640278816223145,
          "tokens_per_second": 151.36119571248943
        }
      ]
    }
  ]
}